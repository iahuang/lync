{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n",
      "0.12.1+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import ctc_segmentation\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, processor and tokenizer\n",
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dummy dataset and read soundfiles\n",
    "SAMPLERATE = 44100\n",
    "waveform, srate = torchaudio.load(\"./cli-test/Nicki Minaj - Anaconda/vocals.wav\")\n",
    "audio = waveform[0, :int(math.ceil(srate*3.5))]\n",
    "transcripts = [\"MY ANACONDA DONT\", \"MY ANACONDA DONT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2687"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'MY ANACONDA DONT', 'start': 0.003723404255319149, 'end': 2.1781914893617023, 'conf': 0.0}, {'text': 'MY ANACONDA DONT', 'start': 2.1781914893617023, 'end': 3.146276595744681, 'conf': 0.0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheoA\\AppData\\Local\\Temp\\ipykernel_29340\\1880113276.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tok_ids = np.array(tok_ids,dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "CHUNKS = 10\n",
    "\n",
    "def align_with_transcript(\n",
    "    audio : np.ndarray,\n",
    "    transcripts : List[str],\n",
    "    samplerate : int = SAMPLERATE,\n",
    "    model : Wav2Vec2ForCTC = model,\n",
    "    processor : Wav2Vec2Processor = processor,\n",
    "    tokenizer : Wav2Vec2CTCTokenizer = tokenizer\n",
    "):\n",
    "    assert audio.ndim == 1\n",
    "\n",
    "    w_len = audio.shape[0]\n",
    "    chunk_len = int(math.ceil(w_len/CHUNKS))\n",
    "    audio_chunks = [audio[i:min(w_len,i+chunk_len)] for i in range(CHUNKS)]\n",
    "    logits_chunks = []\n",
    "    probs_chunks = []\n",
    "    for i in range(CHUNKS):\n",
    "        # Run prediction, get logits and probabilities\n",
    "        inputs = processor(audio_chunks[i], return_tensors=\"pt\", padding=\"longest\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values.to(device)).logits.cpu()[0]\n",
    "            probs = torch.nn.functional.softmax(logits,dim=-1)\n",
    "            logits_chunks.append(logits)\n",
    "            probs_chunks.append(probs)\n",
    "    logits = torch.cat(logits_chunks)\n",
    "    probs = torch.cat(probs_chunks)\n",
    "\n",
    "    # Tokenize transcripts\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    inv_vocab = {v:k for k,v in vocab.items()}\n",
    "    unk_id = vocab[\"<unk>\"]\n",
    "    \n",
    "    tokens = []\n",
    "    for transcript in transcripts:\n",
    "        assert len(transcript) > 0\n",
    "        tok_ids = tokenizer(transcript.replace(\"\\n\",\" \").lower())['input_ids']\n",
    "        tok_ids = np.array(tok_ids,dtype=np.int)\n",
    "        tokens.append(tok_ids[tok_ids != unk_id])\n",
    "    \n",
    "    # Align\n",
    "    char_list = [inv_vocab[i] for i in range(len(inv_vocab))]\n",
    "    config = ctc_segmentation.CtcSegmentationParameters(char_list=char_list)\n",
    "    config.index_duration = audio.shape[0] / probs.size()[0] / samplerate\n",
    "    \n",
    "    ground_truth_mat, utt_begin_indices = ctc_segmentation.prepare_token_list(config, tokens)\n",
    "    timings, char_probs, state_list = ctc_segmentation.ctc_segmentation(config, probs.numpy(), ground_truth_mat)\n",
    "    segments = ctc_segmentation.determine_utterance_segments(config, utt_begin_indices, char_probs, timings, transcripts)\n",
    "    return [{\"text\" : t, \"start\" : p[0], \"end\" : p[1], \"conf\" : p[2]} for t,p in zip(transcripts, segments)]\n",
    "\n",
    "print(align_with_transcript(audio, transcripts, srate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dummy dataset and read soundfiles\n",
    "TARGET_SONG = \"Jimi Hendrix - All Along the Watchtower\"\n",
    "waveform, srate = torchaudio.load(\"./cli-test/\"+TARGET_SONG+\"/vocals.wav\")\n",
    "audio = waveform[0]\n",
    "\n",
    "LYRICS_PATH = \"./cli-test/\"+TARGET_SONG+\".txt\"\n",
    "lyrics_file = open(LYRICS_PATH, 'r')\n",
    "transcript  = lyrics_file.read()\n",
    "transcript_lines = transcript.split(\"\\n\")\n",
    "transcripts = [\"\".join(filter(lambda chr: chr.isalpha() or chr==' ', line)).upper() for line in transcript_lines][:-1] # last one is blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "C:\\Users\\TheoA\\AppData\\Local\\Temp\\ipykernel_29340\\1880113276.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tok_ids = np.array(tok_ids,dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "ctc_output = align_with_transcript(audio, transcripts, srate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'THERE MUST BE SOME KIND OF WAY OUT OF HERE', 'start': 10.02404758259145, 'end': 19.5057778470445, 'conf': 0.0}, {'text': 'SAID THE JOKER TO THE THIEF', 'start': 19.5057778470445, 'end': 21.320268809560268, 'conf': 0.0}, {'text': 'THERES TOO MUCH CONFUSION', 'start': 21.320268809560268, 'end': 36.03216153363811, 'conf': 0.0}, {'text': 'I CANT GET NO RELIEF', 'start': 36.03216153363811, 'end': 44.54575312976209, 'conf': 0.0}, {'text': 'BUSINESSMEN THEY DRINK MY WINE', 'start': 44.54575312976209, 'end': 48.63924474119766, 'conf': 0.0}, {'text': 'PLOWMEN DIG MY EARTH', 'start': 48.63924474119766, 'end': 60.745528443102856, 'conf': 0.0}, {'text': 'NONE WILL LEVEL ON THE LINE', 'start': 60.745528443102856, 'end': 69.76717750873125, 'conf': 0.0}, {'text': 'NOBODY OFFERED HIS WORD', 'start': 69.76717750873125, 'end': 71.16796453179343, 'conf': 0.0}, {'text': 'HEY', 'start': 71.16796453179343, 'end': 71.50183086889633, 'conf': 0.0}, {'text': 'NO REASON TO GET EXCITED', 'start': 71.50183086889633, 'end': 85.17583476241515, 'conf': 0.0}, {'text': 'THE THIEF HE KINDLY SPOKE', 'start': 85.17583476241515, 'end': 93.98700287639171, 'conf': 0.0}, {'text': 'THERE ARE MANY HERE AMONG US', 'start': 93.98700287639171, 'end': 95.43133768255427, 'conf': 0.0}, {'text': 'WHO FEEL THAT LIFE IS BUT A JOKE', 'start': 95.43133768255427, 'end': 110.82547900853804, 'conf': 0.0}, {'text': 'BUT UH BUT YOU AND I WEVE BEEN THROUGH THAT', 'start': 110.82547900853804, 'end': 120.45679703757173, 'conf': 0.0}, {'text': 'AND THIS IS NOT OUR FATE', 'start': 120.45679703757173, 'end': 124.07126303490314, 'conf': 0.0}, {'text': 'SO LET US STOP TALKIN FALSELY NOW', 'start': 124.07126303490314, 'end': 143.64599153852325, 'conf': 0.0}, {'text': 'THE HOURS GETTING LATE', 'start': 143.64599153852325, 'end': 145.22096969398692, 'conf': 0.0}, {'text': 'HEY', 'start': 145.22096969398692, 'end': 145.56935195878995, 'conf': 0.0}, {'text': 'HEY', 'start': 145.56935195878995, 'end': 146.08466739214444, 'conf': 0.0}, {'text': 'ALL ALONG THE WATCHTOWER', 'start': 146.08466739214444, 'end': 160.58607916457044, 'conf': 0.0}, {'text': 'PRINCES KEPT THE VIEW', 'start': 166.88316231015452, 'end': 168.99805926679355, 'conf': 0.0}, {'text': 'WHILE ALL THE WOMEN CAME AND WENT', 'start': 168.99805926679355, 'end': 173.425417215332, 'conf': 0.0}, {'text': 'BAREFOOT SERVANTS TOO', 'start': 173.425417215332, 'end': 185.00912752003268, 'conf': 0.0}, {'text': 'WELL UH OUTSIDE IN THE COLD DISTANCE', 'start': 185.00912752003268, 'end': 195.00334374156952, 'conf': 0.0}, {'text': 'A WILDCAT DID GROWL', 'start': 195.00334374156952, 'end': 209.33782234544407, 'conf': 0.0}, {'text': 'TWO RIDERS WERE APPROACHING', 'start': 209.33782234544407, 'end': 218.14173249557058, 'conf': 0.0}, {'text': 'AND THE WIND BEGAN TO HOWL', 'start': 218.14173249557058, 'end': 220.05783495198725, 'conf': 0.0}, {'text': 'HEY', 'start': 220.05783495198725, 'end': 222.26425596240642, 'conf': 0.0}, {'text': 'ALL ALONG THE WATCHTOWER', 'start': 222.26425596240642, 'end': 241.94785392377744, 'conf': 0.0}, {'text': 'ALL ALONG THE WATCHTOWER', 'start': 241.94785392377744, 'end': 248.06631744938062, 'conf': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "print(ctc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def export_transcript(merged_lines, outfile):\n",
    "    script = {}\n",
    "    script['fragments'] = []\n",
    "    l_id = 0\n",
    "    for line in merged_lines:\n",
    "        fragment = {}\n",
    "        fragment['lines'] = [line['text']]\n",
    "        fragment['begin'] = line['start']\n",
    "        fragment['end'] = line['end']\n",
    "        fragment['language'] = 'eng'\n",
    "        fragment['children'] = []\n",
    "        fragment['id'] = l_id\n",
    "        l_id+=1\n",
    "        script['fragments'].append(fragment)\n",
    "    \n",
    "    json.dump(script, outfile)\n",
    "\n",
    "with open(\"ctc_seg_alignment_aatw.json\", 'w') as f:\n",
    "    export_transcript(ctc_output, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karaoke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b450cb86cfd5959546ccec542814b1b747a819d6eee90d315384aecd3782c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
